import argparse
import json
import os
import sys
from subprocess import run

parser = argparse.ArgumentParser()

# From: https://gist.github.com/amarao/36327a6f77b86b90c2bca72ba03c9d3a
subparsers = parser.add_subparsers(dest='subcommand')
create = subparsers.add_parser("create")
mount = subparsers.add_parser("mount")
update = subparsers.add_parser("update")

for subparser in [ create, mount, update ]:
    subparser.add_argument("Pool")
    subparser.add_argument("-d", "--deduplicated", action="store_true")
    subparser.add_argument("-e", "--encrypted", action="store_true")

create.add_argument("-z", "--zfs-device", required=True)
create.add_argument("-s", "--swap")
mount.add_argument("-b", "--boot-device", required=True)
mount.add_argument("-s", "--swap", action="store_true")
update.add_argument("-p", "--pool", action="store_true")
update.add_argument("-f", "--files", action="store_true")

parser.add_argument("-g", "--generate", action="store_true")
parser.add_argument("-m", "--move", action="store_true")
parser.add_argument("-r", "--rsync", action="store_true")
parser.add_argument("-i", "--install", action="store_true")
parser.add_argument("-H", "--home-manager", action="store_true")
parser.add_argument("-a", "--all", action="store_true")

# Adapted From:
# Answer: https://stackoverflow.com/a/29312757/10827766
# User: https://stackoverflow.com/users/2664549/cgseller
if len(sys.argv) == 1:
    parser.print_help(sys.stderr)
    sys.exit(1)

args = parser.parse_args()

resources = f'{os.environ["HOME"]}/shadowrylander/system/etc/nixos/config'

try:
    if args.subcommand == "create":
        if input('THIS WILL DELETE ALL DATA ON THE SELECTED DEVICE / PARTITION! TO CONTINUE, TYPE IN "ZFS CREATE"!\n\t') == "ZFS CREATE":
            options = {
                "xattr": "sa",
                "acltype": "posixacl",
                "mountpoint": "none",
                "compression": "zstd-19",
                "checksum": "edonr",
                "atime": "off",
                "relatime": "off",
            }
            
            if args.encrypted:
                options["encryption"] = "aes-256-gcm"
                options["keyformat"] = "passphrase"
            if args.deduplicated:
                options["dedup"] = "edonr,verify"
            
            for dataset in run("zfs list -rH", shell = True, capture_output = True).stdout.decode().split("\n"):
                if args.Pool in dataset:
                    run(f"zpool export -f {args.Pool} &> /dev/null", shell = True)
                    break
            
            command = f"zpool create -fo autotrim=on -o altroot=/mnt"
            
            for key, value in options.items():
                command += f" -O {key}={value}"
            
            run(f"{command} {args.Pool} {args.zfs_device}", shell = True)
            
            snapDir = [ "snapdir=visible" ]
            extraCopies = snapDir + [ f"copies={2 if args.encrypted else 3}" ]
            cache = [ "sync=disabled" ]
            ml = "mountpoint=legacy"
            dd = {  }
            ddd = { "datasets": {  }}
            d = "datasets"
            s = "system"
            
            datasets = json.loads('''
                {
                    "base": {  },
                    "hold": {  },
                    "omniverse": {  },
                    "reserved": {  },
                    "system": {
                        "datasets": {
                            "home": { "datasets": { "root": { "mountpoint": "/root" }}},
                            "nix": {  },
                            "persist": {
                                "datasets": {
                                    "cache": {
                                        "datasets": { "root": {  }},
                                        "options": [ "sync=disabled" ]
                                    },
                                    "home": { "datasets": { "root": {  }}}
                                }
                            },
                            "root": {  },
                            "tmp": { "options": [ "sync=disabled" ] }
                        },
                        "options": [ "mountpoint=legacy" ]
                    },
                    "virt": {
                        "datasets": {
                            "docker": {  },
                            "kvm": {  },
                            "podman": { "datasets": {  }},
                            "qemu": {  },
                            "vagrant": {  },
                            "xen": {  }
                        },
                        "options": [ "mountpoint=legacy", "refreservation=none" ],
                        "mountpoint": "/var/lib"
                    }
                }
            '''.strip())
            
            dsd = datasets[s][d]
            
            datasets[args.Pool] = {
                "datasets": {
                    "b": {
                        "datasets": {
                            "a": dd,
                            "cc": { "options": snapDir },
                            "cl": dd,
                            "cj": { "datasets": {
                                "cc": { "options": extraCopies },
                                "m": { "options": snapDir }
                            }},
                            "eb": { "options": extraCopies },
                            "oreo": { "option": snapDir },
                            "p": { "options": snapDir }
                        },
                    },
                    "borg": { "datasets": { "cache": { "options": cache }}},
                    "jails": { "datasets": { "base": dd}},
                    "las": {
                        "datasets": {
                            "dreadnought": ddd,
                            "redstone": ddd,
                            "sinnoh": ddd
                        }
                    },
                    "y": dd,
                    "z": dd
                },
                "options": [ ml ]
            }
            
            users = json.loads('''
                {
                    "primary": "shadowrylander",
                    "secondary": "frost",
                    "nightingale": "curtis"
                }
            '''.strip())
            
            for user in users.values():
                dsd["home"][d][user] = dd
                datasets["virt"][d]["podman"][d][user] = dd
                for dataset in (persist := dsd["persist"][d]).keys():
                    persist[dataset][d][user] = dd
            
            for backup in (las := datasets[args.Pool][d]["las"][d]).keys():
                for zz in [ "zpax", "zsyncs" ]:
                    las[backup][d][zz] = dd
            
            with open(f"{resources}/datasets.nix", "w+") as dnix:
            
                dnix.write("host: {\n")
            
                def recurse(ddict, dname, droot, mountpoint = ""):
            
                    _dataset = f"{droot}/{dname}"
            
                    # cc: clone or create
                    # son: snapshot or none
                    if (dname != "base") and (args.encrypted and args.deduplicated):
                        cc = "clone"
                        son = f"{args.Pool}/base@root"
                    else:
                        cc = "create"
                        son = ""
            
                    _doptions = ddict.get("options", [])
                    if _dataset not in ( f"{args.Pool}/{dataset}" for dataset in (
                        "system",
                        "system/root",
                        "swap",
                        "base",
                        "hold",
                        "omniverse",
                        "reserved",
                    )):
                        pn1 = args.Pool
                        pn2 = f"{pn1}/{pn1}"
            
                        # TODO: Make this such that the current dataset directory
                        #       is placed under the parent directory's mountpoint
                        if (mountpoint := (_mountpoint := ddict.get("mountpoint", ""))) == "":
                            if mountpoint == "":
                                _mountpoint = _dataset.replace(
                                    pn2 if pn2 in _dataset else pn1,
                                    "${host}",
                                    1
                                )
                            else:
                                mountpoint = _mountpoint = f"{mountpoint}/{dname}"
            
                        dnix.write(f'\t"{_dataset}" = "{_mountpoint}";\n')
            
                        for dataset in (ddictd := ddictd.get(
                            d,
                            dd
                        )):
                            recurse(ddictd[dataset], dataset, _dataset, mountpoint)
            
                    doptions = " -o ".join(_doptions)
            
            
            
                    dataset_command = f"zfs {cc} {'-o ' if _doptions else ''} {doptions} {son} {_dataset}"
                    snapshot_command = f"zfs snapshot -r {_dataset}@root"
                    print(dataset_command)
                    print(snapshot_command)
                    
                    run(dataset_command, shell = True)
                    run(snapshot_command, shell = True)
                    
                    print(dataset_command)
                    print(snapshot_command)
            
                for dataset in datasets:
                    recurse(datasets[dataset], dataset, pool_name)
                
                dnix.write("}")
            
            pool_size_plus_metric = run(
                f"zpool get -H size {args.Pool}",
                shell = True,
                capture_output = True
            ).stdout.decode().split("\n")[0].split("\t")[2]
            pool_size = round(float(pool_size_plus_metric[:-1]), 2)
            pool_metric = pool_size_plus_metric[-1]
            
            def pool_percentage_value(percentage):
                return (
                    str(
                        round(
                            (
                                (float(percentage) / 100)
                                * pool_size
                            ),
                            2,
                        )
                    )
                    + pool_metric
                )
            
            # Apparently, if python internal keywords exist in the argument, such as "set", etc.
            # the command errors out; perhaps something to raise an issue of.
            # This seems to work as an alternative.
            run(f"zfs set refreservation={pool_percentage_value(15)} {args.Pool}/reserved", shell = True)
            
            if args.swap:
                _swoptions = [
                    "com.sun:auto-snapshot=false",
                    "compression=zle",
                    "logbias=throughput",
                    "primarycache=metadata",
                    "secondarycache=none"
                    "sync=standard",
                ]
                swoptions = " -o ".join(_swoptions)
            
                ps = run("getconf PAGESIZE", shell = True, capture_output = True).stdout.decode().split("\n")[0]
                run(f"zfs create -V {2**args.swap}G -b {ps} -o {swoptions} {args.Pool}/swap", shell = True)
            
                run(f"mkswap -f /dev/zvol/{args.Pool}/swap", shell = True)
            
            
        else:
            print("Sorry; not continuing!\n\n")

    if args.subcommand == "mount":
        from collections import namedtuple
        from functools import partial
        from os import path as osPath
        from subprocess import DEVNULL
        
        for dataset in run("zfs list -rH", shell = True, capture_output = True).stdout.decode().split("\n"):
            if args.Pool in dataset:
                run(f"zpool export -f {args.Pool} &> /dev/null", shell = True)
                break
        else:
            run(f"zpool import -f {args.Pool}", shell = True)
        
        if args.encrypted:
            run(f"zfs load-key {args.Pool}", shell = True)
        
        if osPath.isdir("/mnt"):
            run("umount -R /mnt", shell = True)
        else:
            run("mkdir /mnt", shell = True)
        
        run(f"mount -t zfs {args.Pool}/system/root /mnt", shell = True)
        
        with open(f"{resources}/datasets.nix") as datasets:
            for dataset in datasets.readlines()[1:-1]:
                dataset = dataset.strip().strip('"')
        
                r = f"{args.Pool}/"
                sr = r + "system/"
                _mount = dataset.replace(
                    sr if sr in dataset else r,
                    '',
                    1
                )
        
                if not osPath.isdir(mount := f"/mnt/{_mount}"):
                    run(f"mkdir -p {mount}", shell = True)
                run(f"mount -t zfs {dataset} {mount}", shell = True)
        
        if not osPath.isdir(boot := "/mnt/boot/efi"):
            run(f"mkdir -p {boot}", shell = True)
        
        run(f"mount {args.boot_device} {boot}", shell = True)
        
        if args.swap:
            run(f"swapon /dev/zvol/{args.Pool}/swap", shell = True)

    if args.subcommand == "update":
        if args.files:
            snapDir = [ "snapdir=visible" ]
            extraCopies = snapDir + [ f"copies={2 if args.encrypted else 3}" ]
            cache = [ "sync=disabled" ]
            ml = "mountpoint=legacy"
            dd = {  }
            ddd = { "datasets": {  }}
            d = "datasets"
            s = "system"
            
            datasets = json.loads('''
                {
                    "base": {  },
                    "hold": {  },
                    "omniverse": {  },
                    "reserved": {  },
                    "system": {
                        "datasets": {
                            "home": { "datasets": { "root": { "mountpoint": "/root" }}},
                            "nix": {  },
                            "persist": {
                                "datasets": {
                                    "cache": {
                                        "datasets": { "root": {  }},
                                        "options": [ "sync=disabled" ]
                                    },
                                    "home": { "datasets": { "root": {  }}}
                                }
                            },
                            "root": {  },
                            "tmp": { "options": [ "sync=disabled" ] }
                        },
                        "options": [ "mountpoint=legacy" ]
                    },
                    "virt": {
                        "datasets": {
                            "docker": {  },
                            "kvm": {  },
                            "podman": { "datasets": {  }},
                            "qemu": {  },
                            "vagrant": {  },
                            "xen": {  }
                        },
                        "options": [ "mountpoint=legacy", "refreservation=none" ],
                        "mountpoint": "/var/lib"
                    }
                }
            '''.strip())
            
            dsd = datasets[s][d]
            
            datasets[args.Pool] = {
                "datasets": {
                    "b": {
                        "datasets": {
                            "a": dd,
                            "cc": { "options": snapDir },
                            "cl": dd,
                            "cj": { "datasets": {
                                "cc": { "options": extraCopies },
                                "m": { "options": snapDir }
                            }},
                            "eb": { "options": extraCopies },
                            "oreo": { "option": snapDir },
                            "p": { "options": snapDir }
                        },
                    },
                    "borg": { "datasets": { "cache": { "options": cache }}},
                    "jails": { "datasets": { "base": dd}},
                    "las": {
                        "datasets": {
                            "dreadnought": ddd,
                            "redstone": ddd,
                            "sinnoh": ddd
                        }
                    },
                    "y": dd,
                    "z": dd
                },
                "options": [ ml ]
            }
            
            users = json.loads('''
                {
                    "primary": "shadowrylander",
                    "secondary": "frost",
                    "nightingale": "curtis"
                }
            '''.strip())
            
            for user in users.values():
                dsd["home"][d][user] = dd
                datasets["virt"][d]["podman"][d][user] = dd
                for dataset in (persist := dsd["persist"][d]).keys():
                    persist[dataset][d][user] = dd
            
            for backup in (las := datasets[args.Pool][d]["las"][d]).keys():
                for zz in [ "zpax", "zsyncs" ]:
                    las[backup][d][zz] = dd
            
            with open(f"{resources}/datasets.nix", "w+") as dnix:
            
                dnix.write("host: {\n")
            
                def recurse(ddict, dname, droot, mountpoint = ""):
            
                    _dataset = f"{droot}/{dname}"
            
                    # cc: clone or create
                    # son: snapshot or none
                    if (dname != "base") and (args.encrypted and args.deduplicated):
                        cc = "clone"
                        son = f"{args.Pool}/base@root"
                    else:
                        cc = "create"
                        son = ""
            
                    _doptions = ddict.get("options", [])
                    if _dataset not in ( f"{args.Pool}/{dataset}" for dataset in (
                        "system",
                        "system/root",
                        "swap",
                        "base",
                        "hold",
                        "omniverse",
                        "reserved",
                    )):
                        pn1 = args.Pool
                        pn2 = f"{pn1}/{pn1}"
            
                        # TODO: Make this such that the current dataset directory
                        #       is placed under the parent directory's mountpoint
                        if (mountpoint := (_mountpoint := ddict.get("mountpoint", ""))) == "":
                            if mountpoint == "":
                                _mountpoint = _dataset.replace(
                                    pn2 if pn2 in _dataset else pn1,
                                    "${host}",
                                    1
                                )
                            else:
                                mountpoint = _mountpoint = f"{mountpoint}/{dname}"
            
                        dnix.write(f'\t"{_dataset}" = "{_mountpoint}";\n')
            
                        for dataset in (ddictd := ddictd.get(
                            d,
                            dd
                        )):
                            recurse(ddictd[dataset], dataset, _dataset, mountpoint)
            
                    doptions = " -o ".join(_doptions)
            
            
            
                for dataset in datasets:
                    recurse(datasets[dataset], dataset, pool_name)
                
                dnix.write("}")
            
        elif args.pool:
            snapDir = [ "snapdir=visible" ]
            extraCopies = snapDir + [ f"copies={2 if args.encrypted else 3}" ]
            cache = [ "sync=disabled" ]
            ml = "mountpoint=legacy"
            dd = {  }
            ddd = { "datasets": {  }}
            d = "datasets"
            s = "system"
            
            datasets = json.loads('''
                {
                    "base": {  },
                    "hold": {  },
                    "omniverse": {  },
                    "reserved": {  },
                    "system": {
                        "datasets": {
                            "home": { "datasets": { "root": { "mountpoint": "/root" }}},
                            "nix": {  },
                            "persist": {
                                "datasets": {
                                    "cache": {
                                        "datasets": { "root": {  }},
                                        "options": [ "sync=disabled" ]
                                    },
                                    "home": { "datasets": { "root": {  }}}
                                }
                            },
                            "root": {  },
                            "tmp": { "options": [ "sync=disabled" ] }
                        },
                        "options": [ "mountpoint=legacy" ]
                    },
                    "virt": {
                        "datasets": {
                            "docker": {  },
                            "kvm": {  },
                            "podman": { "datasets": {  }},
                            "qemu": {  },
                            "vagrant": {  },
                            "xen": {  }
                        },
                        "options": [ "mountpoint=legacy", "refreservation=none" ],
                        "mountpoint": "/var/lib"
                    }
                }
            '''.strip())
            
            dsd = datasets[s][d]
            
            datasets[args.Pool] = {
                "datasets": {
                    "b": {
                        "datasets": {
                            "a": dd,
                            "cc": { "options": snapDir },
                            "cl": dd,
                            "cj": { "datasets": {
                                "cc": { "options": extraCopies },
                                "m": { "options": snapDir }
                            }},
                            "eb": { "options": extraCopies },
                            "oreo": { "option": snapDir },
                            "p": { "options": snapDir }
                        },
                    },
                    "borg": { "datasets": { "cache": { "options": cache }}},
                    "jails": { "datasets": { "base": dd}},
                    "las": {
                        "datasets": {
                            "dreadnought": ddd,
                            "redstone": ddd,
                            "sinnoh": ddd
                        }
                    },
                    "y": dd,
                    "z": dd
                },
                "options": [ ml ]
            }
            
            users = json.loads('''
                {
                    "primary": "shadowrylander",
                    "secondary": "frost",
                    "nightingale": "curtis"
                }
            '''.strip())
            
            for user in users.values():
                dsd["home"][d][user] = dd
                datasets["virt"][d]["podman"][d][user] = dd
                for dataset in (persist := dsd["persist"][d]).keys():
                    persist[dataset][d][user] = dd
            
            for backup in (las := datasets[args.Pool][d]["las"][d]).keys():
                for zz in [ "zpax", "zsyncs" ]:
                    las[backup][d][zz] = dd
            
            with open(f"{resources}/datasets.nix", "w+") as dnix:
            
                dnix.write("host: {\n")
            
                def recurse(ddict, dname, droot, mountpoint = ""):
            
                    _dataset = f"{droot}/{dname}"
            
                    # cc: clone or create
                    # son: snapshot or none
                    if (dname != "base") and (args.encrypted and args.deduplicated):
                        cc = "clone"
                        son = f"{args.Pool}/base@root"
                    else:
                        cc = "create"
                        son = ""
            
                    _doptions = ddict.get("options", [])
                    if _dataset not in ( f"{args.Pool}/{dataset}" for dataset in (
                        "system",
                        "system/root",
                        "swap",
                        "base",
                        "hold",
                        "omniverse",
                        "reserved",
                    )):
                        pn1 = args.Pool
                        pn2 = f"{pn1}/{pn1}"
            
                        # TODO: Make this such that the current dataset directory
                        #       is placed under the parent directory's mountpoint
                        if (mountpoint := (_mountpoint := ddict.get("mountpoint", ""))) == "":
                            if mountpoint == "":
                                _mountpoint = _dataset.replace(
                                    pn2 if pn2 in _dataset else pn1,
                                    "${host}",
                                    1
                                )
                            else:
                                mountpoint = _mountpoint = f"{mountpoint}/{dname}"
            
                        dnix.write(f'\t"{_dataset}" = "{_mountpoint}";\n')
            
                        for dataset in (ddictd := ddictd.get(
                            d,
                            dd
                        )):
                            recurse(ddictd[dataset], dataset, _dataset, mountpoint)
            
                    doptions = " -o ".join(_doptions)
            
            
            
                    dataset_command = f"zfs {cc} {'-o ' if _doptions else ''} {doptions} {son} {_dataset}"
                    snapshot_command = f"zfs snapshot -r {_dataset}@root"
                    print(dataset_command)
                    print(snapshot_command)
                    
                    run(dataset_command, shell = True)
                    run(snapshot_command, shell = True)
                    
                    print(dataset_command)
                    print(snapshot_command)
            
                for dataset in datasets:
                    recurse(datasets[dataset], dataset, pool_name)
                
                dnix.write("}")
            
            pool_size_plus_metric = run(
                f"zpool get -H size {args.Pool}",
                shell = True,
                capture_output = True
            ).stdout.decode().split("\n")[0].split("\t")[2]
            pool_size = round(float(pool_size_plus_metric[:-1]), 2)
            pool_metric = pool_size_plus_metric[-1]
            
            def pool_percentage_value(percentage):
                return (
                    str(
                        round(
                            (
                                (float(percentage) / 100)
                                * pool_size
                            ),
                            2,
                        )
                    )
                    + pool_metric
                )
            
            # Apparently, if python internal keywords exist in the argument, such as "set", etc.
            # the command errors out; perhaps something to raise an issue of.
            # This seems to work as an alternative.
            run(f"zfs set refreservation={pool_percentage_value(15)} {args.Pool}/reserved", shell = True)
            
            if args.swap:
                _swoptions = [
                    "com.sun:auto-snapshot=false",
                    "compression=zle",
                    "logbias=throughput",
                    "primarycache=metadata",
                    "secondarycache=none"
                    "sync=standard",
                ]
                swoptions = " -o ".join(_swoptions)
            
                ps = run("getconf PAGESIZE", shell = True, capture_output = True).stdout.decode().split("\n")[0]
                run(f"zfs create -V {2**args.swap}G -b {ps} -o {swoptions} {args.Pool}/swap", shell = True)
            
                run(f"mkswap -f /dev/zvol/{args.Pool}/swap", shell = True)
            
        else:
            snapDir = [ "snapdir=visible" ]
            extraCopies = snapDir + [ f"copies={2 if args.encrypted else 3}" ]
            cache = [ "sync=disabled" ]
            ml = "mountpoint=legacy"
            dd = {  }
            ddd = { "datasets": {  }}
            d = "datasets"
            s = "system"
            
            datasets = json.loads('''
                {
                    "base": {  },
                    "hold": {  },
                    "omniverse": {  },
                    "reserved": {  },
                    "system": {
                        "datasets": {
                            "home": { "datasets": { "root": { "mountpoint": "/root" }}},
                            "nix": {  },
                            "persist": {
                                "datasets": {
                                    "cache": {
                                        "datasets": { "root": {  }},
                                        "options": [ "sync=disabled" ]
                                    },
                                    "home": { "datasets": { "root": {  }}}
                                }
                            },
                            "root": {  },
                            "tmp": { "options": [ "sync=disabled" ] }
                        },
                        "options": [ "mountpoint=legacy" ]
                    },
                    "virt": {
                        "datasets": {
                            "docker": {  },
                            "kvm": {  },
                            "podman": { "datasets": {  }},
                            "qemu": {  },
                            "vagrant": {  },
                            "xen": {  }
                        },
                        "options": [ "mountpoint=legacy", "refreservation=none" ],
                        "mountpoint": "/var/lib"
                    }
                }
            '''.strip())
            
            dsd = datasets[s][d]
            
            datasets[args.Pool] = {
                "datasets": {
                    "b": {
                        "datasets": {
                            "a": dd,
                            "cc": { "options": snapDir },
                            "cl": dd,
                            "cj": { "datasets": {
                                "cc": { "options": extraCopies },
                                "m": { "options": snapDir }
                            }},
                            "eb": { "options": extraCopies },
                            "oreo": { "option": snapDir },
                            "p": { "options": snapDir }
                        },
                    },
                    "borg": { "datasets": { "cache": { "options": cache }}},
                    "jails": { "datasets": { "base": dd}},
                    "las": {
                        "datasets": {
                            "dreadnought": ddd,
                            "redstone": ddd,
                            "sinnoh": ddd
                        }
                    },
                    "y": dd,
                    "z": dd
                },
                "options": [ ml ]
            }
            
            users = json.loads('''
                {
                    "primary": "shadowrylander",
                    "secondary": "frost",
                    "nightingale": "curtis"
                }
            '''.strip())
            
            for user in users.values():
                dsd["home"][d][user] = dd
                datasets["virt"][d]["podman"][d][user] = dd
                for dataset in (persist := dsd["persist"][d]).keys():
                    persist[dataset][d][user] = dd
            
            for backup in (las := datasets[args.Pool][d]["las"][d]).keys():
                for zz in [ "zpax", "zsyncs" ]:
                    las[backup][d][zz] = dd
            
            with open(f"{resources}/datasets.nix", "w+") as dnix:
            
                dnix.write("host: {\n")
            
                def recurse(ddict, dname, droot, mountpoint = ""):
            
                    _dataset = f"{droot}/{dname}"
            
                    # cc: clone or create
                    # son: snapshot or none
                    if (dname != "base") and (args.encrypted and args.deduplicated):
                        cc = "clone"
                        son = f"{args.Pool}/base@root"
                    else:
                        cc = "create"
                        son = ""
            
                    _doptions = ddict.get("options", [])
                    if _dataset not in ( f"{args.Pool}/{dataset}" for dataset in (
                        "system",
                        "system/root",
                        "swap",
                        "base",
                        "hold",
                        "omniverse",
                        "reserved",
                    )):
                        pn1 = args.Pool
                        pn2 = f"{pn1}/{pn1}"
            
                        # TODO: Make this such that the current dataset directory
                        #       is placed under the parent directory's mountpoint
                        if (mountpoint := (_mountpoint := ddict.get("mountpoint", ""))) == "":
                            if mountpoint == "":
                                _mountpoint = _dataset.replace(
                                    pn2 if pn2 in _dataset else pn1,
                                    "${host}",
                                    1
                                )
                            else:
                                mountpoint = _mountpoint = f"{mountpoint}/{dname}"
            
                        dnix.write(f'\t"{_dataset}" = "{_mountpoint}";\n')
            
                        for dataset in (ddictd := ddictd.get(
                            d,
                            dd
                        )):
                            recurse(ddictd[dataset], dataset, _dataset, mountpoint)
            
                    doptions = " -o ".join(_doptions)
            
            
            
                for dataset in datasets:
                    recurse(datasets[dataset], dataset, pool_name)
                
                dnix.write("}")
            

finally:
    run(f"zpool export -f {args.Pool} &> /dev/null", shell = True)
    sys.exit(0)

if args.generate:
    run("nixos-generate-config --root /mnt", shell = True)

if args.move:
    run("mv /etc/nixos/{,config}/configuration.nix", shell = True)
    run("mv /etc/nixos/{,config}/hardware-configuration.nix", shell = True)

if args.rsync:
    run("nix-env -iA nixos.rsync", shell = True)
    run("rsync -avvczz ~/shadowrylander/system/ /mnt/", shell = True)

if args.install:
    run("nixos-install --show-trace", shell = True)

# TODO
if args.home_manager:
    pass

# TODO: Also include a one-stop-install, mounting, generating, copying, etc. all in one go
if args.all:
    pass
