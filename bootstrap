#!/usr/bin/env python3.9
import argparse
import json
import os
import sys
from subprocess import run, DEVNULL, STDOUT

parser = argparse.ArgumentParser()

# From: https://gist.github.com/amarao/36327a6f77b86b90c2bca72ba03c9d3a
subparsers = parser.add_subparsers(dest='subcommand')
create = subparsers.add_parser("create")
mount = subparsers.add_parser("mount")
update = subparsers.add_parser("update")

for subparser in [ create, mount, update ]:
    subparser.add_argument("Pool")
    subparser.add_argument("-d", "--deduplicated", action="store_true")
    subparser.add_argument("-e", "--encrypted", action="store_true")

create.add_argument("-z", "--zfs-device", required=True)
create.add_argument("-s", "--swap", type=int)
mount.add_argument("-r", "--root-device")
mount.add_argument("-b", "--boot-device")
mount.add_argument("-s", "--swap", action="store_true")
update.add_argument("-p", "--pool", action="store_true")
update.add_argument("-f", "--files", action="store_true")

parser.add_argument("-g", "--generate", action="store_true")
parser.add_argument("-m", "--move", action="store_true")
parser.add_argument("-l", "--link", action="store_true")
parser.add_argument("-r", "--rsync", action="store_true")
parser.add_argument("-i", "--install", action="store_true")
parser.add_argument("-H", "--home-manager", action="store_true")
parser.add_argument("-a", "--all", action="store_true")

# Adapted From:
# Answer: https://stackoverflow.com/a/29312757/10827766
# User: https://stackoverflow.com/users/2664549/cgseller
if len(sys.argv) == 1:
    parser.print_help(sys.stderr)
    sys.exit(1)

args = parser.parse_args()

resources = f'{os.environ["HOME"]}//system/etc/nixos/config'

try:
    if args.subcommand == "create":
        if input('THIS WILL DELETE ALL DATA ON THE SELECTED DEVICE / PARTITION! TO CONTINUE, TYPE IN "ZFS CREATE"!\n\t') == "ZFS CREATE":
            options = {
                "xattr": "sa",
                "acltype": "posixacl",
                "mountpoint": "none",
                "compression": "zstd-19",
                "checksum": "edonr",
                "atime": "off",
                "relatime": "off",
            }
            
            if args.encrypted:
                options["encryption"] = "aes-256-gcm"
                options["keyformat"] = "passphrase"
            if args.deduplicated:
                options["dedup"] = "edonr,verify"
            
            if os.path.isdir("/mnt"):
                run("umount -R /mnt", shell = True, stdout=DEVNULL, stderr=STDOUT)
            else:
                run("mkdir /mnt", shell = True, stdout=DEVNULL, stderr=STDOUT)
            
            run(f"zpool export -f {args.Pool}", shell = True, stdout=DEVNULL, stderr=STDOUT)
            
            command = f"zpool create -fo autotrim=on -o altroot=/mnt -o autoexpand=on"
            
            for key, value in options.items():
                command += f" -O {key}={value}"
            
            run(f"{command} {args.Pool} {args.zfs_device}", shell = True)
            
            snapDir = [ "snapdir=visible" ]
            extraCopies = snapDir + [ f"copies={2 if args.encrypted else 3}" ]
            cache = [ "sync=disabled" ]
            ml = "mountpoint=legacy"
            dd = {  }
            ddd = { "datasets": {  }}
            d = "datasets"
            s = "system"
            
            datasets = json.loads('''
                {
                    "base": {  },
                    "hold": {  },
                    "omniverse": {  },
                    "reserved": {  },
                    "system": {
                        "datasets": {
                            "home": { "datasets": { "root": { "mountpoint": "/root" }}},
                            "nix": {  },
                            "persist": {
                                "datasets": {
                                    "cache": {
                                        "datasets": { "root": {  }},
                                        "options": [ "sync=disabled" ]
                                    },
                                    "home": { "datasets": { "root": {  }}}
                                }
                            },
                            "root": {  },
                            "tmp": { "options": [ "sync=disabled" ] },
                            "etc": {  },
                            "var": {  },
                            "usr": {  },
                            "srv": {  },
                            "opt": {  }
                        },
                        "options": [ "mountpoint=legacy" ]
                    },
                    "virt": {
                        "datasets": {
                            "docker": {  },
                            "kvm": {  },
                            "podman": { "datasets": {  }},
                            "qemu": {  },
                            "vagrant": {  },
                            "xen": {  }
                        },
                        "options": [ "mountpoint=legacy", "refreservation=none" ],
                        "mountpoint": "/var/lib"
                    }
                }
            '''.strip())
            
            dsd = datasets[s][d]
            
            datasets[args.Pool] = {
                "datasets": {
                    "b": {
                        "datasets": {
                            "a": dd,
                            "cc": { "options": snapDir },
                            "cl": dd,
                            "cj": { "datasets": {
                                "cc": { "options": extraCopies },
                                "m": { "options": snapDir }
                            }},
                            "eb": { "options": extraCopies },
                            "oreo": { "option": snapDir },
                            "p": { "options": snapDir }
                        },
                    },
                    "borg": { "datasets": { "cache": { "options": cache }}},
                    "jails": { "datasets": { "base": dd}},
                    "las": {
                        "datasets": {
                            "dreadnought": ddd,
                            "redstone": ddd,
                            "sinnoh": ddd
                        }
                    },
                    "y": dd,
                    "z": dd
                },
                "options": [ ml ]
            }
            
            users = json.loads('''
                {
                    "primary": "",
                    "secondary": "frost",
                    "nightingale": "curtis"
                }
            '''.strip())
            
            for user in users.values():
                dsd["home"][d][user] = dd
                datasets["virt"][d]["podman"][d][user] = dd
                for dataset in (persist := dsd["persist"][d]).keys():
                    persist[dataset][d][user] = dd
            
            for backup in (las := datasets[args.Pool][d]["las"][d]).keys():
                for zz in [ "zpax", "zsyncs" ]:
                    las[backup][d][zz] = dd
            
            with open(f"{resources}/_datasets.nix", "w") as dnix:
            
                dnix.write("host: {\n")
            
                def recurse(ddict, dname, droot, mountpoint = ""):
            
                    _dataset = f"{droot}/{dname}"
            
                    # cc: clone or create
                    # son: snapshot or none
                    if (dname != "base") and (args.encrypted and args.deduplicated):
                        cc = "clone"
                        son = f"{args.Pool}/base@root"
                    else:
                        cc = "create"
                        son = ""
            
                    prefixes = (
                        "system",
                        "system/root",
                        "swap",
                        "base",
                        "hold",
                        "omniverse",
                        "reserved",
                    )
                    _doptions = ddict.get("options", [])
                    if _dataset not in ( f"{args.Pool}/{dataset}" for dataset in prefixes):
                        if (_mountpoint := ddict.get("mountpoint", "")):
                            mountpoint = _mountpoint
                        else:
                            if mountpoint:
                                mountpoint += f"/{dname}"
                                _mountpoint = mountpoint
                            else:
                                _mountpoint = _dataset.removeprefix(args.Pool + "/")
                                for prefix in prefixes:
                                    _mountpoint = _mountpoint.removeprefix(prefix + "/")
                                _mountpoint = "/" + _mountpoint
            
                        dnix.write(f'\t"{_dataset}" = "{_mountpoint}";\n')
            
                    doptions = " -o ".join(_doptions)
                    
                    dataset_command = " ".join(f"zfs {cc} {'-o ' if _doptions else ''} {doptions} {son} {_dataset}".split())
                    snapshot_command = " ".join(f"zfs snapshot -r {_dataset}@root".split())
                    
                    run(dataset_command, shell = True)
                    run(snapshot_command, shell = True)
            
                    for key, value in ddict.get(d, dd).items():
                        recurse(value, key, _dataset, mountpoint)
                
                for key, value in datasets.items():
                    recurse(value, key, args.Pool)
                
                dnix.write("}")
            
            pool_size_plus_metric = run(
                f"zpool get -H size {args.Pool}",
                shell = True,
                capture_output = True
            ).stdout.decode().split("\n")[0].split("\t")[2]
            pool_size = round(float(pool_size_plus_metric[:-1]), 2)
            pool_metric = pool_size_plus_metric[-1]
            
            def pool_percentage_value(percentage):
                return (
                    str(
                        round(
                            (
                                (float(percentage) / 100)
                                * pool_size
                            ),
                            2,
                        )
                    )
                    + pool_metric
                )
            
            # Apparently, if python internal keywords exist in the argument, such as "set", etc.
            # the command errors out; perhaps something to raise an issue of.
            # This seems to work as an alternative.
            run(f"zfs set refreservation={pool_percentage_value(15)} {args.Pool}/reserved", shell = True)
            
            if args.swap:
                _swoptions = [
                    "com.sun:auto-snapshot=false",
                    "compression=zle",
                    "logbias=throughput",
                    "primarycache=metadata",
                    "secondarycache=none",
                    "sync=standard",
                ]
                swoptions = " -o ".join(_swoptions)
            
                ps = run("getconf PAGESIZE", shell = True, capture_output = True).stdout.decode().split("\n")[0]
                swap_command = f"zfs create -V {args.swap}G -b {ps} -o {swoptions} {args.Pool}/swap"
                run(swap_command, shell = True)
            
                run(f"mkswap -f /dev/zvol/{args.Pool}/swap", shell = True)
            
            
        else:
            print("Sorry; not continuing!\n\n")

    if args.subcommand == "update":
        if args.files:
            snapDir = [ "snapdir=visible" ]
            extraCopies = snapDir + [ f"copies={2 if args.encrypted else 3}" ]
            cache = [ "sync=disabled" ]
            ml = "mountpoint=legacy"
            dd = {  }
            ddd = { "datasets": {  }}
            d = "datasets"
            s = "system"
            
            datasets = json.loads('''
                {
                    "base": {  },
                    "hold": {  },
                    "omniverse": {  },
                    "reserved": {  },
                    "system": {
                        "datasets": {
                            "home": { "datasets": { "root": { "mountpoint": "/root" }}},
                            "nix": {  },
                            "persist": {
                                "datasets": {
                                    "cache": {
                                        "datasets": { "root": {  }},
                                        "options": [ "sync=disabled" ]
                                    },
                                    "home": { "datasets": { "root": {  }}}
                                }
                            },
                            "root": {  },
                            "tmp": { "options": [ "sync=disabled" ] },
                            "etc": {  },
                            "var": {  },
                            "usr": {  },
                            "srv": {  },
                            "opt": {  }
                        },
                        "options": [ "mountpoint=legacy" ]
                    },
                    "virt": {
                        "datasets": {
                            "docker": {  },
                            "kvm": {  },
                            "podman": { "datasets": {  }},
                            "qemu": {  },
                            "vagrant": {  },
                            "xen": {  }
                        },
                        "options": [ "mountpoint=legacy", "refreservation=none" ],
                        "mountpoint": "/var/lib"
                    }
                }
            '''.strip())
            
            dsd = datasets[s][d]
            
            datasets[args.Pool] = {
                "datasets": {
                    "b": {
                        "datasets": {
                            "a": dd,
                            "cc": { "options": snapDir },
                            "cl": dd,
                            "cj": { "datasets": {
                                "cc": { "options": extraCopies },
                                "m": { "options": snapDir }
                            }},
                            "eb": { "options": extraCopies },
                            "oreo": { "option": snapDir },
                            "p": { "options": snapDir }
                        },
                    },
                    "borg": { "datasets": { "cache": { "options": cache }}},
                    "jails": { "datasets": { "base": dd}},
                    "las": {
                        "datasets": {
                            "dreadnought": ddd,
                            "redstone": ddd,
                            "sinnoh": ddd
                        }
                    },
                    "y": dd,
                    "z": dd
                },
                "options": [ ml ]
            }
            
            users = json.loads('''
                {
                    "primary": "",
                    "secondary": "frost",
                    "nightingale": "curtis"
                }
            '''.strip())
            
            for user in users.values():
                dsd["home"][d][user] = dd
                datasets["virt"][d]["podman"][d][user] = dd
                for dataset in (persist := dsd["persist"][d]).keys():
                    persist[dataset][d][user] = dd
            
            for backup in (las := datasets[args.Pool][d]["las"][d]).keys():
                for zz in [ "zpax", "zsyncs" ]:
                    las[backup][d][zz] = dd
            
            with open(f"{resources}/_datasets.nix", "w") as dnix:
            
                dnix.write("host: {\n")
            
                def recurse(ddict, dname, droot, mountpoint = ""):
            
                    _dataset = f"{droot}/{dname}"
            
                    # cc: clone or create
                    # son: snapshot or none
                    if (dname != "base") and (args.encrypted and args.deduplicated):
                        cc = "clone"
                        son = f"{args.Pool}/base@root"
                    else:
                        cc = "create"
                        son = ""
            
                    prefixes = (
                        "system",
                        "system/root",
                        "swap",
                        "base",
                        "hold",
                        "omniverse",
                        "reserved",
                    )
                    _doptions = ddict.get("options", [])
                    if _dataset not in ( f"{args.Pool}/{dataset}" for dataset in prefixes):
                        if (_mountpoint := ddict.get("mountpoint", "")):
                            mountpoint = _mountpoint
                        else:
                            if mountpoint:
                                mountpoint += f"/{dname}"
                                _mountpoint = mountpoint
                            else:
                                _mountpoint = _dataset.removeprefix(args.Pool + "/")
                                for prefix in prefixes:
                                    _mountpoint = _mountpoint.removeprefix(prefix + "/")
                                _mountpoint = "/" + _mountpoint
            
                        dnix.write(f'\t"{_dataset}" = "{_mountpoint}";\n')
            
                    for key, value in ddict.get(d, dd).items():
                        recurse(value, key, _dataset, mountpoint)
                
                for key, value in datasets.items():
                    recurse(value, key, args.Pool)
                
                dnix.write("}")
            
        elif args.pool:
            snapDir = [ "snapdir=visible" ]
            extraCopies = snapDir + [ f"copies={2 if args.encrypted else 3}" ]
            cache = [ "sync=disabled" ]
            ml = "mountpoint=legacy"
            dd = {  }
            ddd = { "datasets": {  }}
            d = "datasets"
            s = "system"
            
            datasets = json.loads('''
                {
                    "base": {  },
                    "hold": {  },
                    "omniverse": {  },
                    "reserved": {  },
                    "system": {
                        "datasets": {
                            "home": { "datasets": { "root": { "mountpoint": "/root" }}},
                            "nix": {  },
                            "persist": {
                                "datasets": {
                                    "cache": {
                                        "datasets": { "root": {  }},
                                        "options": [ "sync=disabled" ]
                                    },
                                    "home": { "datasets": { "root": {  }}}
                                }
                            },
                            "root": {  },
                            "tmp": { "options": [ "sync=disabled" ] },
                            "etc": {  },
                            "var": {  },
                            "usr": {  },
                            "srv": {  },
                            "opt": {  }
                        },
                        "options": [ "mountpoint=legacy" ]
                    },
                    "virt": {
                        "datasets": {
                            "docker": {  },
                            "kvm": {  },
                            "podman": { "datasets": {  }},
                            "qemu": {  },
                            "vagrant": {  },
                            "xen": {  }
                        },
                        "options": [ "mountpoint=legacy", "refreservation=none" ],
                        "mountpoint": "/var/lib"
                    }
                }
            '''.strip())
            
            dsd = datasets[s][d]
            
            datasets[args.Pool] = {
                "datasets": {
                    "b": {
                        "datasets": {
                            "a": dd,
                            "cc": { "options": snapDir },
                            "cl": dd,
                            "cj": { "datasets": {
                                "cc": { "options": extraCopies },
                                "m": { "options": snapDir }
                            }},
                            "eb": { "options": extraCopies },
                            "oreo": { "option": snapDir },
                            "p": { "options": snapDir }
                        },
                    },
                    "borg": { "datasets": { "cache": { "options": cache }}},
                    "jails": { "datasets": { "base": dd}},
                    "las": {
                        "datasets": {
                            "dreadnought": ddd,
                            "redstone": ddd,
                            "sinnoh": ddd
                        }
                    },
                    "y": dd,
                    "z": dd
                },
                "options": [ ml ]
            }
            
            users = json.loads('''
                {
                    "primary": "",
                    "secondary": "frost",
                    "nightingale": "curtis"
                }
            '''.strip())
            
            for user in users.values():
                dsd["home"][d][user] = dd
                datasets["virt"][d]["podman"][d][user] = dd
                for dataset in (persist := dsd["persist"][d]).keys():
                    persist[dataset][d][user] = dd
            
            for backup in (las := datasets[args.Pool][d]["las"][d]).keys():
                for zz in [ "zpax", "zsyncs" ]:
                    las[backup][d][zz] = dd
            
            with open(f"{resources}/_datasets.nix", "w") as dnix:
            
                dnix.write("host: {\n")
            
                def recurse(ddict, dname, droot, mountpoint = ""):
            
                    _dataset = f"{droot}/{dname}"
            
                    # cc: clone or create
                    # son: snapshot or none
                    if (dname != "base") and (args.encrypted and args.deduplicated):
                        cc = "clone"
                        son = f"{args.Pool}/base@root"
                    else:
                        cc = "create"
                        son = ""
            
                    prefixes = (
                        "system",
                        "system/root",
                        "swap",
                        "base",
                        "hold",
                        "omniverse",
                        "reserved",
                    )
                    _doptions = ddict.get("options", [])
                    if _dataset not in ( f"{args.Pool}/{dataset}" for dataset in prefixes):
                        if (_mountpoint := ddict.get("mountpoint", "")):
                            mountpoint = _mountpoint
                        else:
                            if mountpoint:
                                mountpoint += f"/{dname}"
                                _mountpoint = mountpoint
                            else:
                                _mountpoint = _dataset.removeprefix(args.Pool + "/")
                                for prefix in prefixes:
                                    _mountpoint = _mountpoint.removeprefix(prefix + "/")
                                _mountpoint = "/" + _mountpoint
            
                        dnix.write(f'\t"{_dataset}" = "{_mountpoint}";\n')
            
                    doptions = " -o ".join(_doptions)
                    
                    dataset_command = " ".join(f"zfs {cc} {'-o ' if _doptions else ''} {doptions} {son} {_dataset}".split())
                    snapshot_command = " ".join(f"zfs snapshot -r {_dataset}@root".split())
                    
                    run(dataset_command, shell = True)
                    run(snapshot_command, shell = True)
            
                    for key, value in ddict.get(d, dd).items():
                        recurse(value, key, _dataset, mountpoint)
                
                for key, value in datasets.items():
                    recurse(value, key, args.Pool)
                
                dnix.write("}")
            
            pool_size_plus_metric = run(
                f"zpool get -H size {args.Pool}",
                shell = True,
                capture_output = True
            ).stdout.decode().split("\n")[0].split("\t")[2]
            pool_size = round(float(pool_size_plus_metric[:-1]), 2)
            pool_metric = pool_size_plus_metric[-1]
            
            def pool_percentage_value(percentage):
                return (
                    str(
                        round(
                            (
                                (float(percentage) / 100)
                                * pool_size
                            ),
                            2,
                        )
                    )
                    + pool_metric
                )
            
            # Apparently, if python internal keywords exist in the argument, such as "set", etc.
            # the command errors out; perhaps something to raise an issue of.
            # This seems to work as an alternative.
            run(f"zfs set refreservation={pool_percentage_value(15)} {args.Pool}/reserved", shell = True)
            
            if args.swap:
                _swoptions = [
                    "com.sun:auto-snapshot=false",
                    "compression=zle",
                    "logbias=throughput",
                    "primarycache=metadata",
                    "secondarycache=none",
                    "sync=standard",
                ]
                swoptions = " -o ".join(_swoptions)
            
                ps = run("getconf PAGESIZE", shell = True, capture_output = True).stdout.decode().split("\n")[0]
                swap_command = f"zfs create -V {args.swap}G -b {ps} -o {swoptions} {args.Pool}/swap"
                run(swap_command, shell = True)
            
                run(f"mkswap -f /dev/zvol/{args.Pool}/swap", shell = True)
            
        else:
            snapDir = [ "snapdir=visible" ]
            extraCopies = snapDir + [ f"copies={2 if args.encrypted else 3}" ]
            cache = [ "sync=disabled" ]
            ml = "mountpoint=legacy"
            dd = {  }
            ddd = { "datasets": {  }}
            d = "datasets"
            s = "system"
            
            datasets = json.loads('''
                {
                    "base": {  },
                    "hold": {  },
                    "omniverse": {  },
                    "reserved": {  },
                    "system": {
                        "datasets": {
                            "home": { "datasets": { "root": { "mountpoint": "/root" }}},
                            "nix": {  },
                            "persist": {
                                "datasets": {
                                    "cache": {
                                        "datasets": { "root": {  }},
                                        "options": [ "sync=disabled" ]
                                    },
                                    "home": { "datasets": { "root": {  }}}
                                }
                            },
                            "root": {  },
                            "tmp": { "options": [ "sync=disabled" ] },
                            "etc": {  },
                            "var": {  },
                            "usr": {  },
                            "srv": {  },
                            "opt": {  }
                        },
                        "options": [ "mountpoint=legacy" ]
                    },
                    "virt": {
                        "datasets": {
                            "docker": {  },
                            "kvm": {  },
                            "podman": { "datasets": {  }},
                            "qemu": {  },
                            "vagrant": {  },
                            "xen": {  }
                        },
                        "options": [ "mountpoint=legacy", "refreservation=none" ],
                        "mountpoint": "/var/lib"
                    }
                }
            '''.strip())
            
            dsd = datasets[s][d]
            
            datasets[args.Pool] = {
                "datasets": {
                    "b": {
                        "datasets": {
                            "a": dd,
                            "cc": { "options": snapDir },
                            "cl": dd,
                            "cj": { "datasets": {
                                "cc": { "options": extraCopies },
                                "m": { "options": snapDir }
                            }},
                            "eb": { "options": extraCopies },
                            "oreo": { "option": snapDir },
                            "p": { "options": snapDir }
                        },
                    },
                    "borg": { "datasets": { "cache": { "options": cache }}},
                    "jails": { "datasets": { "base": dd}},
                    "las": {
                        "datasets": {
                            "dreadnought": ddd,
                            "redstone": ddd,
                            "sinnoh": ddd
                        }
                    },
                    "y": dd,
                    "z": dd
                },
                "options": [ ml ]
            }
            
            users = json.loads('''
                {
                    "primary": "",
                    "secondary": "frost",
                    "nightingale": "curtis"
                }
            '''.strip())
            
            for user in users.values():
                dsd["home"][d][user] = dd
                datasets["virt"][d]["podman"][d][user] = dd
                for dataset in (persist := dsd["persist"][d]).keys():
                    persist[dataset][d][user] = dd
            
            for backup in (las := datasets[args.Pool][d]["las"][d]).keys():
                for zz in [ "zpax", "zsyncs" ]:
                    las[backup][d][zz] = dd
            
            with open(f"{resources}/_datasets.nix", "w") as dnix:
            
                dnix.write("host: {\n")
            
                def recurse(ddict, dname, droot, mountpoint = ""):
            
                    _dataset = f"{droot}/{dname}"
            
                    # cc: clone or create
                    # son: snapshot or none
                    if (dname != "base") and (args.encrypted and args.deduplicated):
                        cc = "clone"
                        son = f"{args.Pool}/base@root"
                    else:
                        cc = "create"
                        son = ""
            
                    prefixes = (
                        "system",
                        "system/root",
                        "swap",
                        "base",
                        "hold",
                        "omniverse",
                        "reserved",
                    )
                    _doptions = ddict.get("options", [])
                    if _dataset not in ( f"{args.Pool}/{dataset}" for dataset in prefixes):
                        if (_mountpoint := ddict.get("mountpoint", "")):
                            mountpoint = _mountpoint
                        else:
                            if mountpoint:
                                mountpoint += f"/{dname}"
                                _mountpoint = mountpoint
                            else:
                                _mountpoint = _dataset.removeprefix(args.Pool + "/")
                                for prefix in prefixes:
                                    _mountpoint = _mountpoint.removeprefix(prefix + "/")
                                _mountpoint = "/" + _mountpoint
            
                        dnix.write(f'\t"{_dataset}" = "{_mountpoint}";\n')
            
                    for key, value in ddict.get(d, dd).items():
                        recurse(value, key, _dataset, mountpoint)
                
                for key, value in datasets.items():
                    recurse(value, key, args.Pool)
                
                dnix.write("}")
            

finally:
    if args.subcommand:
        run(f"zpool export -f {args.Pool}", shell = True, stdout=DEVNULL, stderr=STDOUT)

if args.subcommand == "mount":
    import os
    from collections import namedtuple
    from functools import partial
    from subprocess import DEVNULL
    
    for dataset in run("zfs list -rH", shell = True, capture_output = True).stdout.decode().split("\n"):
        if args.Pool in dataset:
            break
    else:
        run(f"zpool import -f {args.Pool}", shell = True)
    
    if args.encrypted:
        run(f"zfs load-key {args.Pool}", shell = True)
    
    if os.path.isdir("/mnt"):
        run("umount -R /mnt", shell = True, stdout=DEVNULL, stderr=STDOUT)
    else:
        run("mkdir /mnt", shell = True, stdout=DEVNULL, stderr=STDOUT)
    
    if args.root_device:
        run(f"mount {args.root_device} /mnt", shell = True)
    else:
        run(f"mount -t zfs {args.Pool}/system/root /mnt", shell = True)
    
    with open(f"{resources}/_datasets.nix") as datasets:
        for __dataset in datasets.readlines()[1:-1]:
            _dataset, _mount = __dataset.split("=")
            dataset = _dataset.strip()
            mount = '"/mnt' + _mount.strip().lstrip('"').replace(
                "${host}",
                args.Pool,
            )
    
            if not os.path.isdir(mount):
                run(f"mkdir -p {mount}", shell = True)
            mount_command = f"mount -t zfs {dataset} {mount}"
            # print(mount_command)
            run(mount_command, shell = True)
    
    if args.boot_device:
        if not os.path.isdir(boot := "/mnt/boot/efi"):
            run(f"mkdir -p {boot}", shell = True)
        run(f"mount {args.boot_device} {boot}", shell = True)
    
    if args.swap:
        run(f"swapon /dev/zvol/{args.Pool}/swap", shell = True)

if args.generate:
    run("nixos-generate-config --root /mnt", shell = True)

if args.move:
    run("mkdir -p /mnt/etc/nixos/config", shell = True)
    run("mv /mnt/etc/nixos/{,config/}configuration.nix", shell = True)
    run("mv /mnt/etc/nixos/{,config/}hardware-configuration.nix", shell = True)

if args.rsync:
    run("nix-env -iA nixos.rsync", shell = True)
    run("rsync -avvczz ~//system/ /mnt/", shell = True)

if args.install:
    run("nixos-install --show-trace", shell = True)

# TODO
if args.home_manager:
    pass

# TODO: Also include a one-stop-install, mounting, generating, copying, etc. all in one go
if args.all:
    pass
